# -*- coding: utf-8 -*-
"""Red-wine-dataset-EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wQamTcPpqRcGyYLbL9K7W9B0Qnw8jFyx

# Exploratory Data Analysis (EDA)

## 1. Objective
EDA is used to understand the dataset, identify patterns, detect anomalies, and prepare data for machine learning models.

---

## 2. Dataset Overview
- Number of rows and columns
- Feature names and meanings
- Target variable identification
- Data types of features

Methods:
- df.shape
- df.head()
- df.info()

---

## 3. Data Types
- Numerical (int, float)
- Categorical (object, category)
- Ordinal
- Datetime

Purpose:
- Decide preprocessing and encoding strategies

---

## 4. Missing Values
Check:
- Total missing values
- Percentage missing per feature

Handling:
- Drop rows/columns
- Mean / Median / Mode imputation
- Advanced imputation if needed

---

## 5. Statistical Summary
Key metrics:
- Mean, Median, Std
- Min, Max
- Quartiles

Used to:
- Understand spread
- Detect skewness

---

## 6. Univariate Analysis
Analyze single features.

Numerical:
- Histogram
- Boxplot

Categorical:
- Countplot
- Value counts

---

## 7. Bivariate Analysis
Analyze relationships between two variables.

- Numerical vs Numerical → Scatter plot
- Categorical vs Numerical → Boxplot
- Categorical vs Categorical → Crosstab

---

## 8. Multivariate Analysis
Analyze multiple features together.

Tools:
- Correlation matrix
- Heatmaps
- Pairplots

---

## 9. Outlier Detection
Outliers can impact model performance.

Detection methods:
- IQR
- Boxplots
- Z-score

---

## 10. Correlation Analysis
- Identify linear relationships
- Detect multicollinearity
- Correlation ≠ causation

---

## 11. Key Outcomes of EDA
- Clean and structured data
- Feature selection insights
- Preprocessing decisions
- Modeling strategy foundation
"""

# Import the pandas library and assign it the alias 'pd'
# Pandas is used for data manipulation and analysis
import pandas as pd

# Read the CSV file 'winequality-red.csv' and load it into a DataFrame
# A DataFrame is a 2D table-like data structure with rows and columns
df = pd.read_csv('winequality-red.csv')

# Display the first 5 rows of the DataFrame
# This helps quickly inspect the dataset structure and values
df.head()

df.info() #To get info

# Generate descriptive statistics for all numerical columns in the DataFrame
# This includes count, mean, standard deviation, minimum, maximum,and the 25th, 50th (median), and 75th percentiles
df.describe()

# Display the dimensions of the DataFrame
# The output is a tuple: (number_of_rows, number_of_columns)
# Rows represent observations (samples)
# Columns represent features (variables)
df.shape

df.columns #To get all the column names

#Since, output is a numeric value
#To see the valus
df['quality']

# Select the 'quality' column from the DataFrame
# The 'quality' column represents the target variable (wine quality scores)

# Retrieve all unique/distinct values present in the 'quality' column
# This helps understand the range of target classes/labels
df['quality'].unique()
#Basically 6 different values are available

#To see the missing values
df.isnull().sum()
#No missing value there...

#To check for the duplicate records
df.duplicated()

df[df.duplicated()] #to see which duplicate are there, total 239 are there

# Remove duplicate rows from the DataFrame
# Duplicate rows are records where all column values are exactly the same

# inplace=True modifies the original DataFrame directly
# This helps clean the data and prevents duplicate samples from biasing the model
df.drop_duplicates(inplace=True)

# Display the current dimensions of the DataFrame
# The output is a tuple: (number_of_rows, number_of_columns)

# This is often run after data cleaning steps (like removing duplicates)
# to verify how many rows were removed and confirm the updated dataset size
df.shape
#Clearly, the duplicated records are removed

# Compute the pairwise correlation between all numerical columns in the DataFrame
# Correlation measures the strength and direction of the linear relationship
# between two numerical variables
df.corr()

# Import the seaborn library and assign it the alias 'sns'
# Seaborn is a data visualization library built on top of matplotlib
# It is especially useful for statistical visualizations
import seaborn as sns

# Create a heatmap to visualize the correlation matrix of the DataFrame
# df.corr() computes pairwise correlations between numerical features
# The heatmap uses color intensity to show the strength of correlation
sns.heatmap(df.corr())

# Import matplotlib's pyplot module and assign it the alias 'plt'
# Matplotlib is the core plotting library used for creating figures and visualizations
import matplotlib.pyplot as plt

# Import seaborn and assign it the alias 'sns'
# Seaborn provides high-level statistical visualizations built on top of matplotlib
import seaborn as sns

# Create a new figure with a specified size (width=10 inches, height=6 inches)
# This improves readability of the heatmap, especially when many features are present
plt.figure(figsize=(10, 6))

# Generate a heatmap to visualize the correlation matrix
# df.corr() computes pairwise Pearson correlations between numerical features
# annot=True displays the correlation coefficient values inside each cell
sns.heatmap(df.corr(), annot=True)

# Count the number of occurrences of each unique value in the 'quality' column
# This shows how many wine samples belong to each quality score
# It is commonly used to understand class distribution of the target variable
df['quality'].value_counts()

#Conclusion: Imbalanced dataset...!

# Create a bar plot from the value counts
# kind='bar' specifies that the data should be visualized as a bar chart
# Each bar represents a quality score, and its height represents the number of samples
df['quality'].value_counts().plot(kind='bar')
plt.xlabel("Wine quality")
plt.ylabel("Count")
plt.title("Wine quality distribution")
plt.show()

#Seeing first 5 column
df.head()

# Loop through each column (feature) in the DataFrame
# This allows us to analyze the distribution of every feature one by one
for column in df.columns:

    # Create a histogram for the current column
    # sns.histplot() visualizes the distribution of numerical values
    # It helps identify skewness, spread, and potential outliers
    sns.histplot(df[column], kde=True) #kde=True → adds a smooth density curve for better distribution insight
    # Display the plot for the current column
    # plt.show() ensures each histogram is shown separately
    plt.show()

# Create a pairplot for the DataFrame
# A pairplot generates scatter plots for every pair of numerical features
# and histograms (or KDEs) along the diagonal
# It helps visualize relationships, trends, and potential correlations
# between multiple features at once
sns.pairplot(df)

# Create a categorical plot using seaborn
# This plot shows the distribution of 'alcohol' (numerical feature)
# across different categories of 'quality' (categorical/ordinal target variable)

# kind='box' creates a box plot for each quality category
# Box plots help visualize:
# - Median alcohol content
# - Spread (interquartile range)
# - Outliers for each quality score
sns.catplot(x='quality', y='alcohol', data=df, kind='box')

# Create a scatter plot to visualize the relationship between two numerical features
# 'alcohol' is plotted on the x-axis
# 'pH' is plotted on the y-axis

# hue='quality' colors each data point based on the wine quality score
# This helps observe how different quality levels are distributed
# across alcohol content and pH values
sns.scatterplot(x='alcohol', y='pH', hue='quality', data=df)